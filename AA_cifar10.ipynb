{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from utils.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Pour automatiquement recharger les modules externes\n",
    "# voir http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Charger la banque de données CIFAR-10, prétraiter les images et ajouter une dimension pour le biais.\n",
    "    \n",
    "    Input :\n",
    "    - num_training : nombre d'images à mettre dans l'ensemble d'entrainement\n",
    "    - num_validation : nombre d'images à mettre dans l'ensemble de validation\n",
    "    - num_test : nombre d'images à mettre dans l'ensemble de test\n",
    "    - num_dev : d'images à mettre dans l'ensemble dev\n",
    "    \n",
    "    Output :\n",
    "    - X_train, y_train : données et cibles d'entrainement\n",
    "    - X_val, y_val: données et cibles de validation\n",
    "    - X_test y_test: données et cibles de test \n",
    "    - X_dev, y_dev: données et cicles dev\n",
    "    \"\"\"\n",
    "    # Charger les données CIFAR-10\n",
    "    cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "  \n",
    "    # Séparer en ensembles d'entraînement, de validation, de test et de dev\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    X_train = X_train.transpose(0, 3, 1, 2)\n",
    "    X_test = X_test.transpose(0, 3, 1, 2)\n",
    "    X_val = X_val.transpose(0, 3, 1, 2)\n",
    "    X_dev = X_dev.transpose(0, 3, 1, 2)\n",
    "\n",
    "    # Normalisation\n",
    "    X_train -= np.mean(X_train, axis = 0)\n",
    "    X_val -= np.mean(X_val, axis = 0)\n",
    "    X_test -= np.mean(X_test, axis = 0)\n",
    "    X_dev -= np.mean(X_dev, axis = 0)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.BatchNorm import SpatialBatchNorm\n",
    "from layers.Conv import Conv2DCython\n",
    "from layers.Dense import Dense\n",
    "from layers.Flatten import Flatten\n",
    "from layers.MaxPool import MaxPool2DCython\n",
    "from layers.Dropout import Dropout\n",
    "from model.Model import Model\n",
    "from utils.model_loss import cross_entropy_loss_npdl\n",
    "\n",
    "# paramètres de convolution, à modifier au besoin\n",
    "filter_size = 5\n",
    "channels = 3\n",
    "stride = 1\n",
    "p_dropout = 0.1\n",
    "pad = int((filter_size - 1)/2)\n",
    "\n",
    "# paramètres dense\n",
    "num_classes = 10\n",
    "\n",
    "def create_Nlayer_cnn(num_filter_layer1, num_filter_layer2, fc_size, init_weight_scale):\n",
    "    model = Model()\n",
    "    \n",
    "    conv1 = Conv2DCython(num_filter_layer1, filter_size=filter_size, channels=channels, padding=pad, weight_scale=init_weight_scale)\n",
    "    batchnorm1 = SpatialBatchNorm(num_filter_layer1, activation='relu')\n",
    "    dropout1 = Dropout(drop_rate=p_dropout)\n",
    "    maxpool1 = MaxPool2DCython(pooling_size=2, stride=2)\n",
    "\n",
    "    conv2 = Conv2DCython(num_filter_layer2, filter_size=filter_size, channels=num_filter_layer1, padding=pad, weight_scale=init_weight_scale)\n",
    "    batchnorm2 = SpatialBatchNorm(num_filter_layer2, activation='relu')\n",
    "    dropout2 = Dropout(drop_rate=p_dropout)\n",
    "    maxpool2 = MaxPool2DCython(pooling_size=2, stride=2)\n",
    "    \n",
    "    conv_fc1 = Conv2DCython(fc_size, filter_size=8, channels=num_filter_layer2, weight_scale=init_weight_scale, activation='relu')\n",
    "    dropout3 = Dropout(drop_rate=p_dropout)\n",
    "    conv_fc2 = Conv2DCython(num_classes, filter_size=1, channels=fc_size, weight_scale=init_weight_scale)\n",
    "    flatten = Flatten()\n",
    "    \n",
    "    model.add(conv1)\n",
    "    model.add(batchnorm1)\n",
    "    model.add(dropout1)\n",
    "    model.add(maxpool1)\n",
    "\n",
    "    model.add(conv2)\n",
    "    model.add(batchnorm2)\n",
    "    model.add(dropout2)\n",
    "    model.add(maxpool2)\n",
    "\n",
    "    model.add(conv_fc1)\n",
    "    model.add(dropout3)\n",
    "    model.add(conv_fc2)\n",
    "    model.add(flatten)\n",
    "    model.add_loss(cross_entropy_loss_npdl)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = 1e-2 # à ajuster au besoin\n",
    "model = create_Nlayer_cnn(32, 16, 400, reg)\n",
    "\n",
    "model.load_weights(\"cifar10\")\n",
    "\n",
    "item = 1\n",
    "test_image = X_test[item].reshape(1,3,32,32)\n",
    "test_image_target = y_test[item]\n",
    "\n",
    "def softmax(scores):\n",
    "    stable_scores = scores - np.max(scores, axis=1)[:, None]\n",
    "    exp_scores = np.exp(stable_scores)\n",
    "    softmax_output = exp_scores / np.sum(exp_scores, axis=1)[:, None]\n",
    "    return softmax_output\n",
    "\n",
    "print(softmax(model.forward_npdl(test_image, mode='test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization.utils import visualize_as_grid\n",
    "\n",
    "def show_image(X): \n",
    "    W1 = X.transpose(0, 2, 3, 1)\n",
    "    plt.imshow(visualize_as_grid(W1, padding=3).astype('uint8'))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "def show_grayscale(X):\n",
    "    plt.imshow(X, cmap='gray', vmin=np.min(X), vmax=np.max(X))\n",
    "    plt.gca().axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "show_image(test_image)\n",
    "print(test_image_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adverserial_attack import fgsm, jsma, confidence\n",
    "\n",
    "image_adv, perturb = fgsm(model, test_image, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_adv)\n",
    "show_image(perturb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(image_adv))\n",
    "print(confidence(model, image_adv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adverserial_attack import mean_attack_error\n",
    "\n",
    "mse_model = mean_attack_error(model, test_image, image_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Map Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(test_image))\n",
    "print(confidence(model, test_image))\n",
    "print(softmax(model.forward_npdl(test_image, mode='test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.forward_npdl(test_image, mode='test')\n",
    "image_adv = jsma(model, test_image, scores, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(image_adv))\n",
    "print(confidence(model, image_adv))\n",
    "print(softmax(model.forward_npdl(image_adv, mode='test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adverserial_attack import mean_attack_error\n",
    "\n",
    "mse_model = mean_attack_error(model, test_image, image_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple blackbox attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adverserial_attack import simba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(test_image))\n",
    "print(confidence(model, test_image))\n",
    "print(softmax(model.forward_npdl(test_image, mode='test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_predictions = softmax(model.forward_npdl(test_image, mode='test')).reshape(-1,)\n",
    "original_target = model.predict(test_image)\n",
    "\n",
    "delta = simba(model, test_image[0], original_predictions, original_target, eps=2)[np.newaxis,:,:,:]\n",
    "image_adv = test_image[0] + delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict(image_adv))\n",
    "print(confidence(model, image_adv))\n",
    "print(softmax(model.forward_npdl(image_adv, mode='test')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.adverserial_attack import mean_attack_error\n",
    "\n",
    "mse_model = mean_attack_error(model, test_image, image_adv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cartes d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = model.forward_npdl(test_image, mode='test', all=True)\n",
    "X_adv_data = model.forward_npdl(image_adv, mode='test', all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grayscale(X_data['L1'][0, 14, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_grayscale(X_adv_data['L1'][0, 14, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple blackbox attack sur plusieurs images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Permet d'obtenir des valeurs moyennes sur les variations dans les cartes d'activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.adverserial_attack import print_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 50\n",
    "test_set_x = X_test[:nb_samples]\n",
    "test_set_y = y_test[:nb_samples]\n",
    "\n",
    "original_predictions = softmax(model.forward_npdl(test_set_x, mode='test'))\n",
    "original_target = model.predict(test_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utiLise une for loop parce que nous avons implémenté simba pour calculer image_adv d'une seule image\n",
    "adv_set_x = []\n",
    "for i in range(nb_samples):\n",
    "    delta = simba(model, test_set_x[i], original_predictions[i], original_target[i], eps=15)[np.newaxis,:,:,:]\n",
    "    image_adv = test_set_x[i] + delta\n",
    "    adv_set_x.append(image_adv[0])\n",
    "    print(str(i) + '/' + str(nb_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer l'erreur moyenne moyenne des cartes d'activation de chaque couche\n",
    "adv_set_x = np.array(adv_set_x)\n",
    "mse_model = mean_attack_error(model, test_set_x, adv_set_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_mse(mse_model, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
